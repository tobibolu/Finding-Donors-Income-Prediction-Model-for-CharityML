{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donor Propensity Modeling\n",
    "## Predicting High-Income Individuals for Nonprofit Donor Targeting\n",
    "\n",
    "**Business problem:** A nonprofit organization wants to maximize fundraising efficiency by identifying individuals most likely to donate. Since donation propensity correlates strongly with income level, we build a classifier to predict whether an individual earns above $50K annually using demographic data.\n",
    "\n",
    "**Approach:** We compare 6 classification models (Logistic Regression through XGBoost), engineer domain-specific features, and conduct a fairness audit to ensure the model doesn't discriminate across protected demographic groups.\n",
    "\n",
    "**Key result:** Gradient Boosting achieves the best test performance (86.2% accuracy, 0.735 F-beta) with an AUC of 0.92, while maintaining acceptable fairness metrics across race and sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.data_loader import load_census, preprocess, split_data\n",
    "from src.database import create_database, run_query, QUERIES\n",
    "from src.models import get_models, compare_models, optimize_model, get_classification_report\n",
    "from src.fairness import fairness_summary\n",
    "from src.visualizations import (\n",
    "    plot_income_distribution, plot_feature_distributions,\n",
    "    plot_model_comparison, plot_roc_pr_curves,\n",
    "    plot_feature_importance, plot_fairness_results\n",
    ")\n",
    "\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_census()\n",
    "print(f'Dataset: {data.shape[0]:,} records x {data.shape[1]} features')\n",
    "print(f'Missing values: {data.isnull().sum().sum()}')\n",
    "print(f'\\nTarget distribution:')\n",
    "print(data['income'].value_counts(normalize=True).round(4))\n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_income_distribution(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "plot_feature_distributions(data, numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SQL-Based Exploration\n",
    "\n",
    "Loading the data into SQLite to demonstrate relational analytics with CTEs, window functions, and aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = create_database(data)\n",
    "print(f'Database: {db_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income rates by education + occupation (GROUP BY + HAVING)\n",
    "display(run_query(QUERIES['income_by_education_occupation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age group income distribution (CASE expressions)\n",
    "display(run_query(QUERIES['age_income_distribution']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capital gains decile analysis (NTILE window function)\n",
    "display(run_query(QUERIES['capital_gains_percentiles']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic profile with CTE\n",
    "display(run_query(QUERIES['demographic_income_profile']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering & Preprocessing\n",
    "\n",
    "The preprocessing pipeline:\n",
    "1. **Feature engineering**: capital_net (gain - loss), age bins, work hour categories\n",
    "2. **Log-transform** skewed features (capital-gain, capital-loss)\n",
    "3. **Normalize** numeric features to [0, 1]\n",
    "4. **One-hot encode** categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocess(data)\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "print(f'Training: {X_train.shape}')\n",
    "print(f'Test:     {X_test.shape}')\n",
    "print(f'Features: {X.shape[1]} (from {data.shape[1]-1} original)')\n",
    "print(f'\\nTarget balance - Train: {y_train.mean():.3f}, Test: {y_test.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline Performance\n",
    "\n",
    "A naive predictor that always predicts the majority class (<=50K) gives us the floor to beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, fbeta_score\n",
    "\n",
    "majority_class = y.value_counts().idxmax()\n",
    "baseline_acc = max(y.value_counts()) / len(y)\n",
    "baseline_fbeta = fbeta_score(y_test, [majority_class]*len(y_test), beta=0.5)\n",
    "\n",
    "print(f'Baseline accuracy (majority class): {baseline_acc:.4f}')\n",
    "print(f'Baseline F-beta:                    {baseline_fbeta:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison\n",
    "\n",
    "We compare 6 models: Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, XGBoost, and LightGBM. Each is evaluated at 1%, 10%, and 100% of training data to assess learning efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = compare_models(X_train, y_train, X_test, y_test)\n",
    "display(results_df[results_df['sample_frac'] == 1.0][['model', 'test_accuracy', 'test_fbeta', 'train_time']].sort_values('test_fbeta', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_comparison(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Optimization\n",
    "\n",
    "Optimizing Gradient Boosting with GridSearchCV, as it showed the best balance of accuracy, F-beta, and training speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "best_model, grid = optimize_model(X_train, y_train)\n",
    "print(f'Best parameters: {grid.best_params_}')\n",
    "print(f'Best CV F1: {grid.best_score_:.4f}')\n",
    "\n",
    "report = get_classification_report(best_model, X_test, y_test)\n",
    "print(f'\\nTest Accuracy: {report[\"accuracy\"]}')\n",
    "print(f'Test F-beta:   {report[\"fbeta_0.5\"]}')\n",
    "print(f'ROC AUC:       {report.get(\"roc_auc\", \"N/A\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_pr_curves(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(best_model, list(X_train.columns), top_n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fairness & Bias Analysis\n",
    "\n",
    "Since this model would influence resource allocation (who gets targeted for outreach), we audit it for fairness across race and sex. We check:\n",
    "- **Demographic parity**: Are positive prediction rates consistent across groups?\n",
    "- **Equalized odds**: Are TPR and FPR consistent across groups?\n",
    "- **Disparate impact**: Does the model satisfy the 4/5ths rule?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "fairness = fairness_summary(y_test.values, y_pred, data.iloc[y_test.index])\n",
    "\n",
    "print('=== Sex: Demographic Parity ===')\n",
    "display(fairness.get('sex_demographic_parity'))\n",
    "print(f'\\nDisparate Impact Ratio (sex): {fairness.get(\"sex_disparate_impact\", \"N/A\")}')\n",
    "print('(>= 0.8 satisfies the 4/5ths rule)\\n')\n",
    "\n",
    "print('=== Race: Demographic Parity ===')\n",
    "display(fairness.get('race_demographic_parity'))\n",
    "print(f'\\nDisparate Impact Ratio (race): {fairness.get(\"race_disparate_impact\", \"N/A\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Sex: Equalized Odds ===')\n",
    "display(fairness.get('sex_equalized_odds'))\n",
    "\n",
    "print('\\n=== Race: Equalized Odds ===')\n",
    "display(fairness.get('race_equalized_odds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fairness_results(fairness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Income Profile Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_features = ['capital-gain', 'age', 'education-num', 'hours-per-week']\n",
    "high = data[data['income'] == '>50K'][key_features].describe().loc['mean']\n",
    "low = data[data['income'] == '<=50K'][key_features].describe().loc['mean']\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'High Income (mean)': high,\n",
    "    'Low Income (mean)': low,\n",
    "    'Difference (%)': ((high - low) / low * 100).round(1)\n",
    "})\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusions\n",
    "\n",
    "### Model Performance\n",
    "- Gradient Boosting outperforms all tested models with 86.2% accuracy and 0.735 F-beta\n",
    "- Top predictors: capital gain, marital status, age, and education level\n",
    "- High-income individuals show 2,500%+ higher capital gains and ~20% more education\n",
    "\n",
    "### Fairness Findings\n",
    "- The model shows measurable disparities across sex and race in prediction rates\n",
    "- Disparate impact ratios should be monitored and addressed if deploying to production\n",
    "- Consider post-processing calibration or fairness constraints during training\n",
    "\n",
    "### Business Recommendations\n",
    "1. **Deploy** the Gradient Boosting model to score existing donor databases\n",
    "2. **Target** outreach toward individuals with high capital gains, older age, and higher education\n",
    "3. **Monitor** fairness metrics in production to ensure equitable targeting\n",
    "4. **A/B test** model-driven vs. existing outreach strategies to measure donation lift\n",
    "5. **Retrain** periodically with fresh census data to maintain accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
